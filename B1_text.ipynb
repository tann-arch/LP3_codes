{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69aa65c",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ **Assignment Title**\n",
    "\n",
    "> Predict the price of an Uber ride from a given pickup point to the agreed drop-off location.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Theory Overview (What to Say in Viva)**\n",
    "\n",
    "This assignment focuses on **Supervised Machine Learning (Regression)** where we predict a **continuous value** ‚Äî the **fare amount** ‚Äî using features like **distance**, **date-time**, and **passenger count**.\n",
    "\n",
    "### ‚ú≥Ô∏è Concepts Involved\n",
    "\n",
    "| Concept                      | What It Means                                                                                                            |\n",
    "| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Data Preprocessing**       | Cleaning and transforming raw data (removing missing values, fixing invalid lat/lon, extracting date-time info)          |\n",
    "| **Outliers**                 | Extreme data points that distort model performance ‚Äî usually removed with **IQR method** or visualized with **boxplots** |\n",
    "| **Correlation**              | Shows how two features relate; e.g. distance ‚Üî fare (positive correlation)                                               |\n",
    "| **Feature Engineering**      | Creating new features (like ‚Äúdistance‚Äù using Haversine formula)                                                          |\n",
    "| **Linear Regression**        | Predicts values assuming linear relation between inputs and output                                                       |\n",
    "| **Random Forest Regression** | Ensemble of decision trees; handles non-linear data better                                                               |\n",
    "| **Evaluation Metrics**       | R¬≤ (goodness of fit) and RMSE (error magnitude)                                                                          |\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ **Steps in Your Code (Typical Notebook Flow)**\n",
    "\n",
    "Let‚Äôs go step-by-step as your notebook (`B1.ipynb`) likely does.\n",
    "\n",
    "---\n",
    "\n",
    "### **1Ô∏è‚É£ Importing Required Libraries**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "```\n",
    "\n",
    "üìò *Exam Tip:* Be ready to explain why each library is used:\n",
    "\n",
    "* `pandas` ‚Üí data handling\n",
    "* `seaborn/matplotlib` ‚Üí visualization\n",
    "* `sklearn` ‚Üí modeling and evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Loading and Inspecting Dataset**\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"uber.csv\")\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "**What to mention:**\n",
    "\n",
    "* Dataset contains columns like: `pickup_datetime`, `fare_amount`, `pickup_latitude`, `pickup_longitude`, `dropoff_latitude`, `dropoff_longitude`, and `passenger_count`.\n",
    "* `fare_amount` is the **target variable**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3Ô∏è‚É£ Data Cleaning**\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "* Remove missing values:\n",
    "\n",
    "  ```python\n",
    "  df.dropna(inplace=True)\n",
    "  ```\n",
    "* Remove invalid fare values (`fare_amount <= 0`)\n",
    "* Keep valid passenger counts (`1 <= passenger_count <= 6`)\n",
    "* Remove invalid coordinates:\n",
    "\n",
    "  ```python\n",
    "  df = df[(df.pickup_latitude.between(-90, 90)) &\n",
    "          (df.pickup_longitude.between(-180, 180)) &\n",
    "          (df.dropoff_latitude.between(-90, 90)) &\n",
    "          (df.dropoff_longitude.between(-180, 180))]\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4Ô∏è‚É£ Feature Engineering ‚Äî Extracting Date & Time Features**\n",
    "\n",
    "```python\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "df['hour'] = df.pickup_datetime.dt.hour\n",
    "df['day'] = df.pickup_datetime.dt.day\n",
    "df['month'] = df.pickup_datetime.dt.month\n",
    "df['year'] = df.pickup_datetime.dt.year\n",
    "df['dayofweek'] = df.pickup_datetime.dt.dayofweek\n",
    "```\n",
    "\n",
    "**Purpose:**\n",
    "These new features can capture **peak hours** or **seasonal effects** on fare.\n",
    "\n",
    "---\n",
    "\n",
    "### **5Ô∏è‚É£ Compute Distance (Haversine Formula)**\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius (km)\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "df['distance_km'] = haversine(df['pickup_latitude'], df['pickup_longitude'],\n",
    "                              df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6Ô∏è‚É£ Outlier Detection & Removal**\n",
    "\n",
    "**Boxplot Visualization:**\n",
    "\n",
    "```python\n",
    "sns.boxplot(x=df['fare_amount'])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**IQR Method:**\n",
    "\n",
    "```python\n",
    "Q1 = df['fare_amount'].quantile(0.25)\n",
    "Q3 = df['fare_amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['fare_amount'] >= Q1 - 1.5*IQR) & (df['fare_amount'] <= Q3 + 1.5*IQR)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7Ô∏è‚É£ Correlation Check**\n",
    "\n",
    "```python\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "```\n",
    "\n",
    "Expected:\n",
    "Strong positive correlation between **distance_km** and **fare_amount**.\n",
    "\n",
    "---\n",
    "\n",
    "### **8Ô∏è‚É£ Splitting Data**\n",
    "\n",
    "```python\n",
    "X = df[['distance_km', 'passenger_count']]\n",
    "y = df['fare_amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9Ô∏è‚É£ Model 1 ‚Äî Linear Regression**\n",
    "\n",
    "```python\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression R¬≤:\", r2_score(y_test, y_pred_lr))\n",
    "print(\"Linear Regression RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lr)))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **üîü Model 2 ‚Äî Random Forest Regression**\n",
    "\n",
    "```python\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest R¬≤:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "```\n",
    "\n",
    "Expected:\n",
    "Random Forest performs better (higher R¬≤, lower RMSE).\n",
    "\n",
    "---\n",
    "\n",
    "### **üîç 11Ô∏è‚É£ Visualization ‚Äî Actual vs Predicted**\n",
    "\n",
    "```python\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5)\n",
    "plt.xlabel(\"Actual Fare\")\n",
    "plt.ylabel(\"Predicted Fare\")\n",
    "plt.title(\"Random Forest - Actual vs Predicted\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ **Expected Results**\n",
    "\n",
    "| Model             | R¬≤          | RMSE |\n",
    "| ----------------- | ----------- | ---- |\n",
    "| Linear Regression | 0.70 ‚Äì 0.75 | ~5.0 |\n",
    "| Random Forest     | 0.85 ‚Äì 0.90 | ~3.0 |\n",
    "\n",
    "‚úÖ **Conclusion:**\n",
    "Random Forest Regression gives better accuracy because it handles non-linear relationships effectively.\n",
    "\n",
    "---\n",
    "\n",
    "## üí¨ **Viva / Oral Questions and How to Answer**\n",
    "\n",
    "| Question                                                | Short, Confident Answer                                                           |\n",
    "| ------------------------------------------------------- | --------------------------------------------------------------------------------- |\n",
    "| What is Regression?                                     | A supervised ML technique used to predict continuous values.                      |\n",
    "| What is R¬≤ score?                                       | Measures how much variance in target is explained by model. Higher is better.     |\n",
    "| What is RMSE?                                           | Root Mean Square Error ‚Äî measures average prediction error. Lower is better.      |\n",
    "| Why Haversine formula?                                  | To calculate real-world distance between coordinates.                             |\n",
    "| Why remove outliers?                                    | They affect the accuracy and skew the model.                                      |\n",
    "| Difference between Linear Regression and Random Forest? | Linear is simple but assumes linear relation; RF handles complex non-linear data. |\n",
    "| Why use `train_test_split`?                             | To test the model‚Äôs performance on unseen data.                                   |\n",
    "| Which model is better?                                  | Random Forest, due to higher accuracy and robustness.                             |\n",
    "| What is Feature Engineering?                            | Creating new informative variables from existing ones.                            |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **Possible Exam Variations (Be Ready for These Changes)**\n",
    "\n",
    "| Modification Asked             | What to Do                                                            |\n",
    "| ------------------------------ | --------------------------------------------------------------------- |\n",
    "| ‚ÄúAdd another feature‚Äù          | Add `hour` or `dayofweek` to `X`                                      |\n",
    "| ‚ÄúTry different test_size‚Äù      | Change test_size=0.3                                                  |\n",
    "| ‚ÄúShow model accuracy visually‚Äù | Add scatter plot or residual plot                                     |\n",
    "| ‚ÄúAdd feature scaling‚Äù          | Use `StandardScaler` before fitting model                             |\n",
    "| ‚ÄúUse only distance feature‚Äù    | Change `X = df[['distance_km']]`                                      |\n",
    "| ‚ÄúExplain overfitting‚Äù          | Model performs well on training data but poorly on test data          |\n",
    "| ‚ÄúExplain ensemble learning‚Äù    | Combining multiple models (like Random Forest) to improve performance |\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ **Conclusion**\n",
    "\n",
    "In this assignment, we learned:\n",
    "\n",
    "* How to preprocess data and remove outliers\n",
    "* Compute real-world distances using latitude/longitude\n",
    "* Apply **Linear Regression** and **Random Forest Regression**\n",
    "* Evaluate models with **R¬≤** and **RMSE**\n",
    "* Understand the importance of **data quality and feature engineering**\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to generate a **1-page revision sheet (PDF summary)** for this assignment ‚Äî with **viva questions, formulas, key code snippets, and definitions** that you can print and revise before your practical?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2ad55",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
