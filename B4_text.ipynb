{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad06eaac",
   "metadata": {},
   "source": [
    "> **Title:** Implement K-Nearest Neighbors algorithm on `diabetes.csv` dataset.\n",
    "> Compute confusion matrix, accuracy, error rate, precision and recall on the given dataset.\n",
    "\n",
    "Below is a **complete, practical-exam-ready explanation** based on your notebook and the official manual.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© 1Ô∏è‚É£ Objective\n",
    "\n",
    "To use the **K-Nearest Neighbors (KNN)** algorithm to predict whether a patient has diabetes (1) or not (0) using the **PIMA Indian Diabetes Dataset**, and to evaluate the classifier using:\n",
    "\n",
    "* Confusion Matrix\n",
    "* Accuracy\n",
    "* Error Rate\n",
    "* Precision & Recall\n",
    "\n",
    "---\n",
    "\n",
    "## üìò 2Ô∏è‚É£ Theory Concepts\n",
    "\n",
    "### üîπ Supervised Learning\n",
    "\n",
    "We train a model on labeled data `(features ‚Üí target)` so it can learn to predict outcomes for unseen data.\n",
    "\n",
    "### üîπ K-Nearest Neighbors (KNN)\n",
    "\n",
    "| Concept         | Meaning                                                                    |\n",
    "| --------------- | -------------------------------------------------------------------------- |\n",
    "| Type            | Lazy, non-parametric supervised learning                                   |\n",
    "| Working         | Classifies a point based on **majority vote** of its nearest k neighbors   |\n",
    "| Distance Metric | Usually **Euclidean distance**:<br> (\\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + ‚Ä¶}) |\n",
    "| Parameter `k`   | Controls how many neighbors to consult                                     |\n",
    "\n",
    "**Example:**\n",
    "If `k = 5` and 3 neighbors are ‚Äúdiabetic (1)‚Äù and 2 are ‚Äúnon-diabetic (0)‚Äù ‚Üí predict 1.\n",
    "\n",
    "### üîπ Confusion Matrix & Metrics\n",
    "\n",
    "| Term                     | Formula           | Interpretation                               |\n",
    "| ------------------------ | ----------------- | -------------------------------------------- |\n",
    "| **Accuracy**             | (TP + TN) / Total | Overall correctness                          |\n",
    "| **Error Rate**           | 1 ‚Äì Accuracy      | Overall wrongness                            |\n",
    "| **Precision**            | TP / (TP + FP)    | Correct positives out of predicted positives |\n",
    "| **Recall (Sensitivity)** | TP / (TP + FN)    | Correct positives out of actual positives    |\n",
    "| **F1 Score**             | 2 √ó (P√óR)/(P+R)   | Balance of precision and recall              |\n",
    "\n",
    "---\n",
    "\n",
    "## üíª 3Ô∏è‚É£ Typical Code Flow (Explained Line by Line)\n",
    "\n",
    "```python\n",
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "```\n",
    "\n",
    "üìò Imports:\n",
    "\n",
    "* `pandas` / `numpy` ‚Üí data handling\n",
    "* `train_test_split` ‚Üí split dataset\n",
    "* `StandardScaler` ‚Üí feature scaling\n",
    "* `KNeighborsClassifier` ‚Üí KNN model\n",
    "* `metrics` ‚Üí evaluation tools\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 2. Load Dataset\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()\n",
    "df.shape\n",
    "```\n",
    "\n",
    "Displays first 5 rows and dataset shape.\n",
    "Typical shape: (768 rows, 9 columns).\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 3. Check for missing values\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "Ensures data is complete (this dataset normally has none).\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 4. Feature / Target split\n",
    "X = df.iloc[:, :-1]   # first 8 columns = features\n",
    "y = df.iloc[:, -1]    # last column  = Outcome (0 or 1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 5. Split into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "80 % for training, 20 % for testing.\n",
    "`random_state=42` ‚Üí reproducible results.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 6. Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.transform(X_test)\n",
    "```\n",
    "\n",
    "KNN is distance-based ‚Üí scaling ensures each feature has equal influence.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 7. Create and Train KNN Model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "`k = 5` neighbors. Model memorizes training data.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 8. Make Predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 9. Evaluate Model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "error_rate = 1 - accuracy\n",
    "```\n",
    "\n",
    "Generates metrics.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 10. Display Results\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error Rate:\", error_rate)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "```\n",
    "\n",
    "Typical Output Example:\n",
    "\n",
    "```\n",
    "Confusion Matrix:\n",
    "[[92  15]\n",
    " [18  29]]\n",
    "Accuracy = 0.79\n",
    "Error Rate = 0.21\n",
    "Precision = 0.659\n",
    "Recall = 0.617\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 11. Optional ‚Äì Accuracy vs K Plot\n",
    "\n",
    "```python\n",
    "acc_list = []\n",
    "for k in range(1, 21):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    acc_list.append(model.score(X_test, y_test))\n",
    "\n",
    "plt.plot(range(1, 21), acc_list, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs k')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Helps decide optimal k (usually 7‚Äì11 gives best accuracy).\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ 4Ô∏è‚É£ Expected Results\n",
    "\n",
    "| Metric         | Typical Value Range |\n",
    "| -------------- | ------------------- |\n",
    "| **Accuracy**   | 0.76 ‚Äì 0.82         |\n",
    "| **Precision**  | 0.65 ‚Äì 0.70         |\n",
    "| **Recall**     | 0.60 ‚Äì 0.65         |\n",
    "| **Error Rate** | 0.18 ‚Äì 0.24         |\n",
    "\n",
    "‚úÖ Balanced classifier ‚Äî works well for binary health data.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† 5Ô∏è‚É£ Viva Questions & Answers\n",
    "\n",
    "| Question                                 | Short Answer                                                                        |\n",
    "| ---------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "| What is KNN?                             | Supervised ML algorithm that classifies based on nearest neighbors.                 |\n",
    "| Why scale features?                      | Because KNN depends on distance; scaling makes units comparable.                    |\n",
    "| How is k chosen?                         | By testing different values and picking one with highest accuracy or lowest error.  |\n",
    "| What is overfitting in KNN?              | Very small k fits noise ‚Üí poor generalization.                                      |\n",
    "| What is Confusion Matrix?                | Table of TP, TN, FP, FN predictions.                                                |\n",
    "| Difference between Precision and Recall? | Precision = quality of positive predictions, Recall = coverage of actual positives. |\n",
    "| What is Error Rate?                      | Portion of incorrect predictions = 1 ‚Äì accuracy.                                    |\n",
    "| What happens if k is too large?          | Model becomes too smooth ‚Üí underfits.                                               |\n",
    "| When to use KNN?                         | When data is small & distance meaningful.                                           |\n",
    "\n",
    "---\n",
    "\n",
    "## üß© 6Ô∏è‚É£ Possible Modifications Examiner May Ask + How to Do Them\n",
    "\n",
    "| Request                             | What to Change               | Code                                                                                        |\n",
    "| ----------------------------------- | ---------------------------- | ------------------------------------------------------------------------------------------- |\n",
    "| **‚ÄúTry a different k.‚Äù**            | Change neighbors             | `knn = KNeighborsClassifier(n_neighbors=7)`                                                 |\n",
    "| **‚ÄúShow accuracy for multiple k.‚Äù** | Loop k from 1 to 20 and plot | *(see plot code above)*                                                                     |\n",
    "| **‚ÄúAdd cross-validation.‚Äù**         | Use `cross_val_score()`      | `from sklearn.model_selection import cross_val_score; cross_val_score(knn,X,y,cv=5).mean()` |\n",
    "| **‚ÄúShow ROC curve.‚Äù**               | Use `roc_curve` & `auc`      | `from sklearn.metrics import roc_curve,auc`                                                 |\n",
    "| **‚ÄúNormalize with MinMaxScaler.‚Äù**  | Change scaler                | `from sklearn.preprocessing import MinMaxScaler`                                            |\n",
    "| **‚ÄúAdd Random Forest comparison.‚Äù** | Import and train RF          | `from sklearn.ensemble import RandomForestClassifier`                                       |\n",
    "\n",
    "---\n",
    "\n",
    "## üìà 7Ô∏è‚É£ Interpretation & Insights\n",
    "\n",
    "* The model can flag potential diabetic patients for further checkup.\n",
    "* Balanced Precision/Recall means low false positives and false negatives.\n",
    "* Increasing `k` smooths the decision boundary.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ 8Ô∏è‚É£ Conclusion\n",
    "\n",
    "> We preprocessed the PIMA Diabetes dataset, scaled features, applied the K-Nearest Neighbors algorithm, and evaluated the model using Accuracy, Precision, Recall, and Error Rate.\n",
    "> The model achieved ~80 % accuracy and proved effective for binary classification tasks like diabetes prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## üóíÔ∏è 9Ô∏è‚É£ Quick Exam Revision Sheet\n",
    "\n",
    "**Keywords:** KNN, Supervised Learning, Distance Metric, Feature Scaling, Confusion Matrix, Precision, Recall, Error Rate, Accuracy\n",
    "\n",
    "**Formulas**\n",
    "\n",
    "* Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "* Error Rate = 1 ‚Äì Accuracy\n",
    "* Precision = TP/(TP+FP)\n",
    "* Recall = TP/(TP+FN)\n",
    "* F1 = 2 √ó (P√óR)/(P+R)\n",
    "\n",
    "**Common Steps**\n",
    "\n",
    "1. Import Libraries\n",
    "2. Load Dataset\n",
    "3. Split Train/Test\n",
    "4. Scale Features\n",
    "5. Train KNN\n",
    "6. Predict & Evaluate\n",
    "7. Compute Confusion Matrix\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to make a **visual confusion matrix heatmap** and **accuracy-vs-k graph code snippet** (they look great for submission notebooks and viva demos)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7062dd3e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
